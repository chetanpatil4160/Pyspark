{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPajcDaU+yl19vVjH8iOzAL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chetanpatil4160/Pyspark/blob/main/Spark_Coiding_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdCJisTIvq9D",
        "outputId": "99162d6c-1070-4439-8b5d-eaa3ac730415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"interview\").getOrCreate()"
      ],
      "metadata": {
        "id": "GFCOvfUayY68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "6p2INUjgyuCh",
        "outputId": "2bf2ed7d-076c-446e-b5e7-e2f1dba9fa8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e0a86ab37d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://609efa6f567f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>interview</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data (login_date is now a string)\n",
        "data = [\n",
        "    (101, 1, \"2024-02-01\", 3),\n",
        "    (101, 1, \"2024-02-02\", 3),\n",
        "    (102, 2, \"2024-02-01\", 2),\n",
        "    (103, 1, \"2024-02-02\", 5),\n",
        "    (104, 3, \"2024-02-03\", 1),\n",
        "    (105, 2, \"2024-02-03\", 4),\n",
        "    (101, 1, \"2024-02-04\", 2),\n",
        "    (102, 2, \"2024-02-05\", 3),\n",
        "    (103, 1, \"2024-02-06\", 6),\n",
        "    (104, 3, \"2024-02-07\", 2),\n",
        "    (105, 2, \"2024-02-07\", 3),\n",
        "    (106, 2, \"2024-02-08\", 1),\n",
        "    (107, 1, \"2024-02-08\", 5),\n",
        "    (108, 3, \"2024-02-09\", 2),\n",
        "    (109, 3, \"2024-02-09\", 4),\n",
        "    (101, 2, \"2024-02-01\", 1),  # Existing extra entry\n",
        "\n",
        "    # New entries for users with continuous logins:\n",
        "    (103, 1, \"2024-02-07\", 7),  # 103 logged in on 2024-02-06, so add for 2024-02-07\n",
        "    (101, 1, \"2024-02-05\", 3),  # 101 logged in on 2024-02-04, so add for 2024-02-05\n",
        "    (105, 2, \"2024-02-08\", 4)   # 105 logged in on 2024-02-07, so add for 2024-02-08\n",
        "]\n",
        "\n",
        "\n",
        "coloumns=[\"user_id\",\"kit_id\",\"login_date\",\"session_count\"]\n",
        "\n",
        "df = spark.createDataFrame(data,coloumns)"
      ],
      "metadata": {
        "id": "NtCRZlNCy15E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "#df1 = df.withColumn(\"login_date\",df.login_date.cast(DateType()))\n",
        "\n",
        "df1 = df.withColumn(\"login_date\",to_date(col(\"login_date\"),\"yyyy-MM-dd\"))\n",
        "\n",
        "df1.createOrReplaceTempView(\"orders\")"
      ],
      "metadata": {
        "id": "QCMwS8B51JTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwGT_GyC2M68",
        "outputId": "a5322532-f42e-48bd-c26d-f9968011279a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+----------+-------------+\n",
            "|user_id|kit_id|login_date|session_count|\n",
            "+-------+------+----------+-------------+\n",
            "|    101|     1|2024-02-01|            3|\n",
            "|    101|     1|2024-02-02|            3|\n",
            "|    102|     2|2024-02-01|            2|\n",
            "|    103|     1|2024-02-02|            5|\n",
            "|    104|     3|2024-02-03|            1|\n",
            "|    105|     2|2024-02-03|            4|\n",
            "|    101|     1|2024-02-04|            2|\n",
            "|    102|     2|2024-02-05|            3|\n",
            "|    103|     1|2024-02-06|            6|\n",
            "|    104|     3|2024-02-07|            2|\n",
            "|    105|     2|2024-02-07|            3|\n",
            "|    106|     2|2024-02-08|            1|\n",
            "|    107|     1|2024-02-08|            5|\n",
            "|    108|     3|2024-02-09|            2|\n",
            "|    109|     3|2024-02-09|            4|\n",
            "|    101|     2|2024-02-01|            1|\n",
            "|    103|     1|2024-02-07|            7|\n",
            "|    101|     1|2024-02-05|            3|\n",
            "|    105|     2|2024-02-08|            4|\n",
            "+-------+------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by user_id and finding the first login date for each user\n",
        "df.groupBy(df.user_id).agg(min(df.login_date).alias(\"first_login_date\")).show()\n",
        "\n",
        "# Equivalent SQL query to achieve the same result using Spark SQL\n",
        "spark.sql(\"\"\"\n",
        "            SELECT user_id, MIN(login_date) AS first_login_date\n",
        "            FROM orders\n",
        "            GROUP BY user_id\n",
        "            ORDER BY user_id\n",
        "\"\"\").show()\n",
        "\n",
        "\n",
        "# Importing Window function for window operations\n",
        "# Defining a window partitioned by user_id and ordered by login_date\n",
        "# Assigning a row number to each login date within each user_id partition\n",
        "# Filtering to keep only the first login date (row number = 1)\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "window_spec = Window.partitionBy(df.user_id).orderBy(df.login_date)\n",
        "\n",
        "df.withColumn(\"row_num\", row_number().over(window_spec)) \\\n",
        "  .filter(col(\"row_num\") == 1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_Ffo7FJ2VO6",
        "outputId": "bb880509-0ca1-43a5-b069-636313cf3e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------+\n",
            "|user_id|first_login_date|\n",
            "+-------+----------------+\n",
            "|    101|      2024-02-01|\n",
            "|    102|      2024-02-01|\n",
            "|    103|      2024-02-02|\n",
            "|    104|      2024-02-03|\n",
            "|    105|      2024-02-03|\n",
            "|    106|      2024-02-08|\n",
            "|    107|      2024-02-08|\n",
            "|    108|      2024-02-09|\n",
            "|    109|      2024-02-09|\n",
            "+-------+----------------+\n",
            "\n",
            "+-------+----------------+\n",
            "|user_id|first_login_date|\n",
            "+-------+----------------+\n",
            "|    101|      2024-02-01|\n",
            "|    102|      2024-02-01|\n",
            "|    103|      2024-02-02|\n",
            "|    104|      2024-02-03|\n",
            "|    105|      2024-02-03|\n",
            "|    106|      2024-02-08|\n",
            "|    107|      2024-02-08|\n",
            "|    108|      2024-02-09|\n",
            "|    109|      2024-02-09|\n",
            "+-------+----------------+\n",
            "\n",
            "+-------+------+----------+-------------+-------+\n",
            "|user_id|kit_id|login_date|session_count|row_num|\n",
            "+-------+------+----------+-------------+-------+\n",
            "|    101|     1|2024-02-01|            3|      1|\n",
            "|    102|     2|2024-02-01|            2|      1|\n",
            "|    103|     1|2024-02-02|            5|      1|\n",
            "|    104|     3|2024-02-03|            1|      1|\n",
            "|    105|     2|2024-02-03|            4|      1|\n",
            "|    106|     2|2024-02-08|            1|      1|\n",
            "|    107|     1|2024-02-08|            5|      1|\n",
            "|    108|     3|2024-02-09|            2|      1|\n",
            "|    109|     3|2024-02-09|            4|      1|\n",
            "+-------+------+----------+-------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Question 2 - Find Out The Kit Id Use by Each Player On First Day`**"
      ],
      "metadata": {
        "id": "tRoip8ctHmyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Partitioning the data by user_id and ordering it by login_date in ascending order\n",
        "window_spec = Window.partitionBy(df.user_id).orderBy(df.login_date)\n",
        "\n",
        "# Add a new column \"rank\" using dense_rank() function\n",
        "# This assigns a rank to each row within the user_id partition based on login_date\n",
        "df_with_rank = df.withColumn(\"rank\", dense_rank().over(window_spec))\n",
        "\n",
        "# Filter rows where rank is 1 (earliest login for each user)\n",
        "df_with_rank.filter(col(\"rank\") == 1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtZ5gQTRDDYa",
        "outputId": "b26cc227-24d5-4279-d15f-145216e3de33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+----------+-------------+----+\n",
            "|user_id|kit_id|login_date|session_count|rank|\n",
            "+-------+------+----------+-------------+----+\n",
            "|    101|     1|2024-02-01|            3|   1|\n",
            "|    101|     2|2024-02-01|            1|   1|\n",
            "|    102|     2|2024-02-01|            2|   1|\n",
            "|    103|     1|2024-02-02|            5|   1|\n",
            "|    104|     3|2024-02-03|            1|   1|\n",
            "|    105|     2|2024-02-03|            4|   1|\n",
            "|    106|     2|2024-02-08|            1|   1|\n",
            "|    107|     1|2024-02-08|            5|   1|\n",
            "|    108|     3|2024-02-09|            2|   1|\n",
            "|    109|     3|2024-02-09|            4|   1|\n",
            "+-------+------+----------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**` For Same Question Above Show Kit Id in Array Instead Of Different Row`**\n"
      ],
      "metadata": {
        "id": "63hE3BxvISqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec = Window.partitionBy(df.user_id).orderBy(df.login_date)\n",
        "\n",
        "# Add a new column \"rank\" using dense_rank() function\n",
        "# This assigns a rank to each row within the user_id partition based on login_date\n",
        "df_with_rank = df.withColumn(\"rank\", dense_rank().over(window_spec))\n",
        "\n",
        "# Filter rows where rank is 1 (earliest login for each user)\n",
        "kit_used = df_with_rank.filter(col(\"rank\") == 1) \\\n",
        ".groupby(col(\"user_id\")) \\\n",
        ".agg(collect_list(col(\"kit_id\")).alias(\"kit_id\"))\n",
        "\n",
        "kit_used.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOsE0hiQIe7T",
        "outputId": "f79ea44a-3acc-42f7-eea8-7d02d5611516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+\n",
            "|user_id|kit_id|\n",
            "+-------+------+\n",
            "|    101|[1, 2]|\n",
            "|    102|   [2]|\n",
            "|    103|   [1]|\n",
            "|    104|   [3]|\n",
            "|    105|   [2]|\n",
            "|    106|   [2]|\n",
            "|    107|   [1]|\n",
            "|    108|   [3]|\n",
            "|    109|   [3]|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate games Played by each Users**"
      ],
      "metadata": {
        "id": "YRc7B1S2Mt_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import sum\n",
        "\n",
        "# Define window: partition by user_id, ordered by login_date, cumulative sum\n",
        "running_dum = Window.partitionBy(df.user_id).orderBy(df.login_date).rowsBetween(Window.unboundedPreceding, 0)\n",
        "\n",
        "# Add running total column\n",
        "running_total = df.withColumn(\"running_total\", sum(\"session_count\").over(running_dum))\n",
        "running_total.show()\n",
        "\n",
        "\n",
        "# Calculate the running total of session_count for each user\n",
        "spark.sql(\"\"\"SELECT user_id,\n",
        "       login_date,\n",
        "       session_count,\n",
        "       SUM(session_count) OVER (\n",
        "           PARTITION BY user_id\n",
        "           ORDER BY login_date\n",
        "           ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "       ) AS running_total\n",
        "FROM orders\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5sfMwMNKJU1",
        "outputId": "d5ddc5d1-77ac-4f64-e4b8-98c6b4cfa5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+----------+-------------+-------------+\n",
            "|user_id|kit_id|login_date|session_count|running_total|\n",
            "+-------+------+----------+-------------+-------------+\n",
            "|    101|     1|2024-02-01|            3|            3|\n",
            "|    101|     2|2024-02-01|            1|            4|\n",
            "|    101|     1|2024-02-02|            3|            7|\n",
            "|    101|     1|2024-02-04|            2|            9|\n",
            "|    101|     1|2024-02-05|            3|           12|\n",
            "|    102|     2|2024-02-01|            2|            2|\n",
            "|    102|     2|2024-02-05|            3|            5|\n",
            "|    103|     1|2024-02-02|            5|            5|\n",
            "|    103|     1|2024-02-06|            6|           11|\n",
            "|    103|     1|2024-02-07|            7|           18|\n",
            "|    104|     3|2024-02-03|            1|            1|\n",
            "|    104|     3|2024-02-07|            2|            3|\n",
            "|    105|     2|2024-02-03|            4|            4|\n",
            "|    105|     2|2024-02-07|            3|            7|\n",
            "|    105|     2|2024-02-08|            4|           11|\n",
            "|    106|     2|2024-02-08|            1|            1|\n",
            "|    107|     1|2024-02-08|            5|            5|\n",
            "|    108|     3|2024-02-09|            2|            2|\n",
            "|    109|     3|2024-02-09|            4|            4|\n",
            "+-------+------+----------+-------------+-------------+\n",
            "\n",
            "+-------+----------+-------------+-------------+\n",
            "|user_id|login_date|session_count|running_total|\n",
            "+-------+----------+-------------+-------------+\n",
            "|    101|2024-02-01|            3|            3|\n",
            "|    101|2024-02-01|            1|            4|\n",
            "|    101|2024-02-02|            3|            7|\n",
            "|    101|2024-02-04|            2|            9|\n",
            "|    101|2024-02-05|            3|           12|\n",
            "|    102|2024-02-01|            2|            2|\n",
            "|    102|2024-02-05|            3|            5|\n",
            "|    103|2024-02-02|            5|            5|\n",
            "|    103|2024-02-06|            6|           11|\n",
            "|    103|2024-02-07|            7|           18|\n",
            "|    104|2024-02-03|            1|            1|\n",
            "|    104|2024-02-07|            2|            3|\n",
            "|    105|2024-02-03|            4|            4|\n",
            "|    105|2024-02-07|            3|            7|\n",
            "|    105|2024-02-08|            4|           11|\n",
            "|    106|2024-02-08|            1|            1|\n",
            "|    107|2024-02-08|            5|            5|\n",
            "|    108|2024-02-09|            2|            2|\n",
            "|    109|2024-02-09|            4|            4|\n",
            "+-------+----------+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find out The Users Who Has logged in continously**"
      ],
      "metadata": {
        "id": "A-EEg-hjRdpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Compute the next login date per user and filter logins occurring on the same or next day\n",
        "Window = Window.partitionBy(df.user_id).orderBy(df.login_date)\n",
        "\n",
        "df.withColumn(\"next_date\", lead(\"login_date\").over(Window).alias(\"next_date\")) \\\n",
        ".withColumn(\"diff\", datediff(col(\"next_date\"), col(\"login_date\"))) \\\n",
        ".filter(col(\"diff\").isin([0,1])).show()\n",
        "\n",
        "\n",
        "\n",
        "# Findout out the users which come first day as well as next day\n",
        "df.withColumn(\"next_date\", lead(\"login_date\").over(Window).alias(\"next_date\")) \\\n",
        ".withColumn(\"first_login_date\", first(\"login_date\").over(Window).alias(\"first_login_date\")) \\\n",
        ".withColumn(\"diff\", datediff(col(\"next_date\"), col(\"first_login_date\"))) \\\n",
        ".filter(col(\"diff\") == 1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpyexdh6PKh9",
        "outputId": "ffef35b5-d1ef-4214-9787-a9ab22013a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+----------+-------------+----------+----+\n",
            "|user_id|kit_id|login_date|session_count| next_date|diff|\n",
            "+-------+------+----------+-------------+----------+----+\n",
            "|    101|     1|2024-02-01|            3|2024-02-01|   0|\n",
            "|    101|     2|2024-02-01|            1|2024-02-02|   1|\n",
            "|    101|     1|2024-02-04|            2|2024-02-05|   1|\n",
            "|    103|     1|2024-02-06|            6|2024-02-07|   1|\n",
            "|    105|     2|2024-02-07|            3|2024-02-08|   1|\n",
            "+-------+------+----------+-------------+----------+----+\n",
            "\n",
            "+-------+------+----------+-------------+----------+----------------+----+\n",
            "|user_id|kit_id|login_date|session_count| next_date|first_login_date|diff|\n",
            "+-------+------+----------+-------------+----------+----------------+----+\n",
            "|    101|     2|2024-02-01|            1|2024-02-02|      2024-02-01|   1|\n",
            "+-------+------+----------+-------------+----------+----------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8YJSdY71Rq21"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}